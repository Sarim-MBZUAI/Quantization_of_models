{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Loss: 0.1304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|██████████| 1/1 [02:23<00:00, 143.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 validation images: 97.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "_ = torch.manual_seed(0)\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor() ,\n",
    "\n",
    "transforms.Normalize((0.1307,),(0.3081,))\n",
    "\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "mnist_trainset = datasets.MNIST(root='./data', train=True, download=False, transform=transform)\n",
    "mnist_testset = datasets.MNIST(root='./data', train=False, download=False, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(mnist_trainset, batch_size=10, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_testset, batch_size=10, shuffle=False)\n",
    "\n",
    "# device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# for quantization we have to put device = \"cpu\"\n",
    "\n",
    "device = \"cpu\"\n",
    "\n",
    "class SimplifiedVGG16(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(SimplifiedVGG16, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(256 * 3 * 3, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(1024, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "model = SimplifiedVGG16(num_classes=10).to(device)\n",
    "\n",
    "\n",
    "num_classes = 10\n",
    "num_epochs = 1\n",
    "batch_size = 10\n",
    "learning_rate = 0.005\n",
    "\n",
    "model =SimplifiedVGG16(num_classes).to(device)\n",
    "\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay = 0.005, momentum = 0.9)  \n",
    "\n",
    "\n",
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "\n",
    "\n",
    "for epoch in tqdm(range(num_epochs), desc=\"Epochs\"):\n",
    "    model.train()\n",
    "    train_loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=False)\n",
    "    for i, (images, labels) in enumerate(train_loop):  \n",
    "        # Move tensors to the configured device\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update progress bar\n",
    "        train_loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "            \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        val_loop = tqdm(test_loader, desc=\"Validation\", leave=False)\n",
    "        for images, labels in val_loop:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            del images, labels, outputs\n",
    "\n",
    "            # Update progress bar\n",
    "            val_loop.set_postfix(accuracy=f\"{100 * correct / total:.2f}%\")\n",
    "    \n",
    "        print(f'Accuracy of the network on the {total} validation images: {100 * correct / total:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 1000/1000 [00:06<00:00, 153.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.978\n",
      "wrong counts for the digit 0: 2\n",
      "wrong counts for the digit 1: 6\n",
      "wrong counts for the digit 2: 26\n",
      "wrong counts for the digit 3: 8\n",
      "wrong counts for the digit 4: 42\n",
      "wrong counts for the digit 5: 18\n",
      "wrong counts for the digit 6: 28\n",
      "wrong counts for the digit 7: 13\n",
      "wrong counts for the digit 8: 52\n",
      "wrong counts for the digit 9: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    wrong_counts = [0 for i in range(10)]\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for data in tqdm(test_loader , desc='Testing'):\n",
    "\n",
    "                x,y = data\n",
    "\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)\n",
    "                output = model(x)\n",
    "\n",
    "                for idx , i in enumerate(output):\n",
    "\n",
    "                    if torch.argmax(i) == y[idx]:\n",
    "                        correct += 1\n",
    "                    else:\n",
    "                        wrong_counts[y[idx]] +=1\n",
    "                    total+=1\n",
    "    print(f'Accuracy: {round(correct/total, 3)}')\n",
    "    for i in range(len(wrong_counts)):\n",
    "        print(f'wrong counts for the digit {i}: {wrong_counts[i]}')\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model successfully\n",
      "Successfully loaded model from disk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurm-sarim.hashmi-35128/ipykernel_3567072/3950831590.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(MODEL_FILENAME))\n"
     ]
    }
   ],
   "source": [
    "# Now lets print the size of model before quantization\n",
    "\n",
    "def print_size_of_model(model):\n",
    "\n",
    "    torch.save(model.state_dict() , \"temp_vgg.p\")\n",
    "    print(\"Size (KB) :\" , os.path.getsize(\"temp_vgg.p\")/1e3)\n",
    "    os.remove(\"temp_vgg.p\")\n",
    "\n",
    "MODEL_FILENAME = \"SimplifiedVGG16.pt\"\n",
    "\n",
    "torch.save(model.state_dict() , MODEL_FILENAME)\n",
    "print(\"Saved model successfully\")\n",
    "model.load_state_dict(torch.load(MODEL_FILENAME))\n",
    "print(\"Successfully loaded model from disk\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now lets see the weights before quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight before quantization\n",
      "Parameter containing:\n",
      "tensor([[[[-0.1353, -0.1419, -0.0434],\n",
      "          [ 0.0388,  0.0791, -0.0228],\n",
      "          [ 0.1248,  0.0267,  0.0808]]],\n",
      "\n",
      "\n",
      "        [[[-0.0350, -0.0234,  0.0229],\n",
      "          [ 0.0282, -0.0279, -0.0343],\n",
      "          [-0.0321,  0.0044,  0.0125]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1268,  0.1575,  0.1537],\n",
      "          [-0.0658, -0.0330,  0.0969],\n",
      "          [-0.1846, -0.1450, -0.0596]]],\n",
      "\n",
      "\n",
      "        [[[-0.1512, -0.1831, -0.1003],\n",
      "          [ 0.0767,  0.0528, -0.0415],\n",
      "          [ 0.0990,  0.0571,  0.1365]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1077,  0.0938, -0.0885],\n",
      "          [ 0.1360, -0.0003, -0.1176],\n",
      "          [ 0.1051, -0.0671, -0.0822]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0459, -0.0513,  0.0994],\n",
      "          [-0.0632, -0.0711,  0.1102],\n",
      "          [-0.0419,  0.0420,  0.1134]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1847,  0.2070,  0.2334],\n",
      "          [-0.0818, -0.0393, -0.1071],\n",
      "          [-0.1200, -0.2150, -0.0980]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2195,  0.0905, -0.1054],\n",
      "          [ 0.1940, -0.0363, -0.1808],\n",
      "          [ 0.2136,  0.0860, -0.1380]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1894,  0.2157,  0.1224],\n",
      "          [-0.0796, -0.0303,  0.0200],\n",
      "          [-0.2123, -0.1351, -0.0079]]],\n",
      "\n",
      "\n",
      "        [[[-0.0419, -0.0553, -0.0267],\n",
      "          [ 0.0010, -0.0184,  0.0157],\n",
      "          [-0.0299, -0.0479, -0.0045]]],\n",
      "\n",
      "\n",
      "        [[[-0.0804, -0.1048,  0.0068],\n",
      "          [-0.0449, -0.1036, -0.0743],\n",
      "          [ 0.1749,  0.1292,  0.0317]]],\n",
      "\n",
      "\n",
      "        [[[-0.0926,  0.0798,  0.0980],\n",
      "          [-0.0126,  0.1396,  0.1621],\n",
      "          [ 0.1310,  0.1163,  0.0405]]],\n",
      "\n",
      "\n",
      "        [[[-0.1416, -0.0850,  0.1013],\n",
      "          [-0.0905, -0.0467,  0.1132],\n",
      "          [-0.0933,  0.0466,  0.1858]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1005,  0.1372,  0.1219],\n",
      "          [-0.0542,  0.0916,  0.0479],\n",
      "          [ 0.0614, -0.0143,  0.0895]]],\n",
      "\n",
      "\n",
      "        [[[-0.0667,  0.0617,  0.0519],\n",
      "          [-0.0777, -0.0194, -0.0694],\n",
      "          [-0.0412, -0.0058, -0.0766]]],\n",
      "\n",
      "\n",
      "        [[[-0.0831, -0.0799,  0.0579],\n",
      "          [ 0.0045, -0.0992, -0.0758],\n",
      "          [ 0.1107, -0.0076, -0.0565]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0594, -0.0100, -0.0890],\n",
      "          [-0.0824, -0.1199, -0.0770],\n",
      "          [ 0.1248,  0.0230,  0.1719]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1479,  0.1530, -0.1553],\n",
      "          [ 0.0886,  0.1017, -0.1939],\n",
      "          [ 0.1988,  0.1949, -0.0637]]],\n",
      "\n",
      "\n",
      "        [[[-0.0343,  0.0663,  0.0049],\n",
      "          [-0.0758, -0.0948, -0.0290],\n",
      "          [ 0.0445,  0.0460, -0.0690]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0176,  0.0933,  0.1157],\n",
      "          [ 0.1260,  0.1335, -0.0824],\n",
      "          [ 0.0823, -0.0876, -0.1082]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0888,  0.1070, -0.0675],\n",
      "          [-0.0429,  0.1191, -0.0387],\n",
      "          [-0.0864,  0.0779,  0.1139]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0242, -0.0815,  0.1138],\n",
      "          [ 0.0697,  0.2045,  0.1706],\n",
      "          [ 0.1440,  0.1714, -0.0369]]],\n",
      "\n",
      "\n",
      "        [[[-0.1053, -0.1091, -0.0542],\n",
      "          [ 0.0472,  0.0951,  0.0603],\n",
      "          [ 0.0335,  0.0277,  0.0456]]],\n",
      "\n",
      "\n",
      "        [[[-0.0610,  0.0751, -0.0486],\n",
      "          [ 0.0221, -0.0217, -0.0548],\n",
      "          [-0.0257, -0.0126,  0.0061]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0681, -0.2268, -0.2180],\n",
      "          [ 0.1818, -0.0540, -0.0802],\n",
      "          [ 0.2153,  0.1661,  0.1281]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1017,  0.1213,  0.1663],\n",
      "          [ 0.1181,  0.0420,  0.1132],\n",
      "          [-0.2072, -0.1787, -0.1398]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1203, -0.0324, -0.1365],\n",
      "          [ 0.0711, -0.0244, -0.0600],\n",
      "          [ 0.1218,  0.0803, -0.0768]]],\n",
      "\n",
      "\n",
      "        [[[-0.0774, -0.0462,  0.0773],\n",
      "          [-0.0190,  0.0314,  0.1219],\n",
      "          [ 0.1031,  0.0460,  0.0205]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1211,  0.1674,  0.0244],\n",
      "          [ 0.0004,  0.1192,  0.0333],\n",
      "          [-0.1494, -0.0018,  0.1135]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0462, -0.0832, -0.0055],\n",
      "          [ 0.0499, -0.0452, -0.1044],\n",
      "          [ 0.1352,  0.0178,  0.0682]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0817, -0.0739, -0.0728],\n",
      "          [ 0.0715,  0.0987, -0.0742],\n",
      "          [-0.0393,  0.0905,  0.0387]]],\n",
      "\n",
      "\n",
      "        [[[-0.0643, -0.1052, -0.1219],\n",
      "          [-0.0688, -0.1047,  0.0611],\n",
      "          [-0.1587,  0.0388,  0.1251]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0814,  0.1439, -0.1102],\n",
      "          [-0.0164,  0.1526, -0.0522],\n",
      "          [ 0.0940,  0.1661,  0.1325]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1371,  0.0601, -0.0531],\n",
      "          [ 0.0140,  0.1569,  0.1692],\n",
      "          [-0.1661, -0.0788,  0.1079]]],\n",
      "\n",
      "\n",
      "        [[[-0.0270, -0.1198, -0.0839],\n",
      "          [-0.0351, -0.0452, -0.0863],\n",
      "          [ 0.1441,  0.1394,  0.0119]]],\n",
      "\n",
      "\n",
      "        [[[-0.0574,  0.0354,  0.0485],\n",
      "          [ 0.0207,  0.0428, -0.0591],\n",
      "          [-0.0281, -0.0698, -0.0365]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1958,  0.0567, -0.2485],\n",
      "          [ 0.1625,  0.1348, -0.0600],\n",
      "          [ 0.0807,  0.2088,  0.1964]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0313,  0.0294,  0.1447],\n",
      "          [ 0.1221,  0.1372,  0.0398],\n",
      "          [ 0.0542, -0.0282, -0.1529]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1201, -0.1205, -0.0597],\n",
      "          [ 0.1303, -0.0245, -0.0455],\n",
      "          [ 0.0895,  0.0800,  0.0481]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0736,  0.0855, -0.0512],\n",
      "          [ 0.0200, -0.0480, -0.0253],\n",
      "          [ 0.0049,  0.0935,  0.0685]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1128,  0.0292, -0.1065],\n",
      "          [ 0.0019,  0.1326,  0.0942],\n",
      "          [-0.0702,  0.0306,  0.1186]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1137,  0.0191,  0.0378],\n",
      "          [-0.0322,  0.1034,  0.1114],\n",
      "          [-0.0793, -0.1203,  0.0617]]],\n",
      "\n",
      "\n",
      "        [[[-0.0704, -0.0622,  0.0955],\n",
      "          [-0.0640, -0.0663,  0.1243],\n",
      "          [-0.0273, -0.0395,  0.1057]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0050,  0.1013,  0.1274],\n",
      "          [-0.0980, -0.0117,  0.1081],\n",
      "          [-0.0940, -0.1318,  0.0188]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1405,  0.1585,  0.0977],\n",
      "          [ 0.1577,  0.1607, -0.1370],\n",
      "          [ 0.1693, -0.0562, -0.1532]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0487,  0.1401,  0.1218],\n",
      "          [-0.0056,  0.1524,  0.1128],\n",
      "          [ 0.0529,  0.1419,  0.1198]]],\n",
      "\n",
      "\n",
      "        [[[-0.0925, -0.2370, -0.1510],\n",
      "          [ 0.0679, -0.0685, -0.0526],\n",
      "          [ 0.1304,  0.2269,  0.1934]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0208, -0.0585, -0.0147],\n",
      "          [-0.0688,  0.0181, -0.0437],\n",
      "          [-0.0571,  0.0260, -0.0547]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0355, -0.0173,  0.1099],\n",
      "          [-0.0538,  0.0186,  0.1228],\n",
      "          [ 0.0331,  0.0312,  0.0279]]],\n",
      "\n",
      "\n",
      "        [[[-0.0785, -0.0437, -0.0243],\n",
      "          [-0.0590, -0.0866, -0.0422],\n",
      "          [-0.0544,  0.1231,  0.1424]]],\n",
      "\n",
      "\n",
      "        [[[-0.0281,  0.0267, -0.0801],\n",
      "          [ 0.1100,  0.0562,  0.1508],\n",
      "          [ 0.0374, -0.0258,  0.1065]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0702, -0.0274, -0.0623],\n",
      "          [ 0.1043, -0.0720, -0.0558],\n",
      "          [-0.0101,  0.0588,  0.0563]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0311,  0.0586,  0.0883],\n",
      "          [-0.0920, -0.0296,  0.0310],\n",
      "          [-0.0581, -0.0297, -0.0995]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1986,  0.1623, -0.0844],\n",
      "          [ 0.2153,  0.0213, -0.1688],\n",
      "          [ 0.1014, -0.1307, -0.2062]]],\n",
      "\n",
      "\n",
      "        [[[-0.1588, -0.0281,  0.1284],\n",
      "          [ 0.1197,  0.1347,  0.1200],\n",
      "          [ 0.1251,  0.0010,  0.1105]]],\n",
      "\n",
      "\n",
      "        [[[-0.1125, -0.1913, -0.0538],\n",
      "          [ 0.1263,  0.1297,  0.2195],\n",
      "          [ 0.1447,  0.1534,  0.0185]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1353,  0.2195,  0.2109],\n",
      "          [-0.1377, -0.0999,  0.0114],\n",
      "          [-0.1372, -0.1723, -0.1291]]],\n",
      "\n",
      "\n",
      "        [[[-0.0923, -0.0873,  0.0590],\n",
      "          [-0.0745, -0.0286,  0.0638],\n",
      "          [ 0.0270,  0.1026,  0.1228]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1658,  0.0340, -0.1765],\n",
      "          [ 0.1214,  0.0994,  0.0278],\n",
      "          [-0.0346,  0.2027,  0.1775]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0138,  0.0550,  0.1024],\n",
      "          [-0.0906, -0.1001,  0.0121],\n",
      "          [-0.0111,  0.0114, -0.0969]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0450,  0.1630,  0.0861],\n",
      "          [-0.1016,  0.0363,  0.1059],\n",
      "          [-0.1429, -0.1841, -0.0725]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0989,  0.1469,  0.0618],\n",
      "          [-0.0545, -0.0615,  0.0261],\n",
      "          [-0.0929, -0.0679, -0.0891]]],\n",
      "\n",
      "\n",
      "        [[[-0.0029, -0.1518, -0.0553],\n",
      "          [-0.0374, -0.1099,  0.0044],\n",
      "          [ 0.1584,  0.1392,  0.1239]]],\n",
      "\n",
      "\n",
      "        [[[-0.0748, -0.0647,  0.1371],\n",
      "          [-0.0111, -0.0734,  0.0917],\n",
      "          [-0.0828, -0.0627, -0.0111]]]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(\"Weight before quantization\")\n",
    "\n",
    "# weights of the 1st layer\n",
    "\n",
    "print(model.features[0].weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Size of the model before quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the model before quantization in KB\n",
      "Size (KB) : 13325.89\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Size of the model before quantization in KB\")\n",
    "\n",
    "print_size_of_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Quantizedvgg16(\n",
       "  (quant): QuantStub(\n",
       "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  )\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(\n",
       "      1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "      (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "    )\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(\n",
       "      64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "      (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "    )\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(\n",
       "      128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "      (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "    )\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(\n",
       "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "      (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "    )\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(\n",
       "      in_features=2304, out_features=1024, bias=True\n",
       "      (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "    )\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(\n",
       "      in_features=1024, out_features=10, bias=True\n",
       "      (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "    )\n",
       "  )\n",
       "  (dequant): DeQuantStub()\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Quantizedvgg16(nn.Module):\n",
    "\n",
    "    def __init__(self , num_classes = 10):\n",
    "        super(Quantizedvgg16,self).__init__()\n",
    "        self.quant = torch.quantization.QuantStub()\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(256 * 3 * 3, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(1024, num_classes),\n",
    "        )\n",
    "        self.dequant = torch.quantization.DeQuantStub()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.quant(x)\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        x = self.dequant(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model_quantized = Quantizedvgg16(num_classes=10).to(device)\n",
    "\n",
    "# Copy the weight of unquantized model\n",
    "\n",
    "model_quantized.load_state_dict(model.state_dict())\n",
    "\n",
    "model_quantized.eval()\n",
    "\n",
    "model_quantized.qconfig = torch.ao.quantization.default_qconfig\n",
    "\n",
    "model_quantized = torch.ao.quantization.prepare(model_quantized)\n",
    "\n",
    "\n",
    "model_quantized\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 1000/1000 [00:06<00:00, 146.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.978\n",
      "wrong counts for the digit 0: 2\n",
      "wrong counts for the digit 1: 6\n",
      "wrong counts for the digit 2: 26\n",
      "wrong counts for the digit 3: 8\n",
      "wrong counts for the digit 4: 42\n",
      "wrong counts for the digit 5: 18\n",
      "wrong counts for the digit 6: 28\n",
      "wrong counts for the digit 7: 13\n",
      "wrong counts for the digit 8: 52\n",
      "wrong counts for the digit 9: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    wrong_counts = [0 for i in range(10)]\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for data in tqdm(test_loader , desc='Testing'):\n",
    "\n",
    "                x,y = data\n",
    "\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)\n",
    "                output = model_quantized(x)\n",
    "\n",
    "                for idx , i in enumerate(output):\n",
    "\n",
    "                    if torch.argmax(i) == y[idx]:\n",
    "                        correct += 1\n",
    "                    else:\n",
    "                        wrong_counts[y[idx]] +=1\n",
    "                    total+=1\n",
    "    print(f'Accuracy: {round(correct/total, 3)}')\n",
    "    for i in range(len(wrong_counts)):\n",
    "        print(f'wrong counts for the digit {i}: {wrong_counts[i]}')\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Quantizedvgg16(\n",
       "  (quant): QuantStub(\n",
       "    (activation_post_process): MinMaxObserver(min_val=-0.4242129623889923, max_val=2.821486711502075)\n",
       "  )\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(\n",
       "      1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "      (activation_post_process): MinMaxObserver(min_val=-2.094406843185425, max_val=3.05881404876709)\n",
       "    )\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(\n",
       "      64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "      (activation_post_process): MinMaxObserver(min_val=-5.384039878845215, max_val=6.796621322631836)\n",
       "    )\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(\n",
       "      128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "      (activation_post_process): MinMaxObserver(min_val=-5.604202747344971, max_val=6.492345333099365)\n",
       "    )\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(\n",
       "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "      (activation_post_process): MinMaxObserver(min_val=-8.341008186340332, max_val=7.212594985961914)\n",
       "    )\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(\n",
       "      in_features=2304, out_features=1024, bias=True\n",
       "      (activation_post_process): MinMaxObserver(min_val=-2.874377965927124, max_val=4.539828300476074)\n",
       "    )\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(\n",
       "      in_features=1024, out_features=10, bias=True\n",
       "      (activation_post_process): MinMaxObserver(min_val=-7.512662887573242, max_val=14.790718078613281)\n",
       "    )\n",
       "  )\n",
       "  (dequant): DeQuantStub()\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the stats of various layers\n",
    "\n",
    "model_quantized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the stats of quantized layers\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Quantizedvgg16(\n",
       "  (quant): Quantize(scale=tensor([0.0256]), zero_point=tensor([17]), dtype=torch.quint8)\n",
       "  (features): Sequential(\n",
       "    (0): QuantizedConv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.040576543658971786, zero_point=52, padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): QuantizedConv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.09591072052717209, zero_point=56, padding=(1, 1))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): QuantizedConv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.09524840861558914, zero_point=59, padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.12246931344270706, zero_point=68, padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): QuantizedLinear(in_features=2304, out_features=1024, scale=0.058379579335451126, zero_point=49, qscheme=torch.per_tensor_affine)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): QuantizedLinear(in_features=1024, out_features=10, scale=0.17561717331409454, zero_point=43, qscheme=torch.per_tensor_affine)\n",
       "  )\n",
       "  (dequant): DeQuantize()\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_quantized = torch.ao.quantization.convert(model_quantized)\n",
    "\n",
    "print(\"Checking the stats of quantized layers\")\n",
    "\n",
    "model_quantized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now weights after quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights after quantization\n",
      "tensor([[[[ -69,  -73,  -22],\n",
      "          [  20,   41,  -12],\n",
      "          [  64,   14,   41]]],\n",
      "\n",
      "\n",
      "        [[[ -18,  -12,   12],\n",
      "          [  14,  -14,  -18],\n",
      "          [ -16,    2,    6]]],\n",
      "\n",
      "\n",
      "        [[[  65,   81,   79],\n",
      "          [ -34,  -17,   50],\n",
      "          [ -95,  -74,  -31]]],\n",
      "\n",
      "\n",
      "        [[[ -78,  -94,  -51],\n",
      "          [  39,   27,  -21],\n",
      "          [  51,   29,   70]]],\n",
      "\n",
      "\n",
      "        [[[  55,   48,  -45],\n",
      "          [  70,    0,  -60],\n",
      "          [  54,  -34,  -42]]],\n",
      "\n",
      "\n",
      "        [[[  24,  -26,   51],\n",
      "          [ -32,  -36,   57],\n",
      "          [ -21,   22,   58]]],\n",
      "\n",
      "\n",
      "        [[[  95,  106,  120],\n",
      "          [ -42,  -20,  -55],\n",
      "          [ -62, -110,  -50]]],\n",
      "\n",
      "\n",
      "        [[[ 113,   46,  -54],\n",
      "          [ 100,  -19,  -93],\n",
      "          [ 110,   44,  -71]]],\n",
      "\n",
      "\n",
      "        [[[  97,  111,   63],\n",
      "          [ -41,  -16,   10],\n",
      "          [-109,  -69,   -4]]],\n",
      "\n",
      "\n",
      "        [[[ -21,  -28,  -14],\n",
      "          [   1,   -9,    8],\n",
      "          [ -15,  -25,   -2]]],\n",
      "\n",
      "\n",
      "        [[[ -41,  -54,    3],\n",
      "          [ -23,  -53,  -38],\n",
      "          [  90,   66,   16]]],\n",
      "\n",
      "\n",
      "        [[[ -47,   41,   50],\n",
      "          [  -6,   72,   83],\n",
      "          [  67,   60,   21]]],\n",
      "\n",
      "\n",
      "        [[[ -73,  -44,   52],\n",
      "          [ -46,  -24,   58],\n",
      "          [ -48,   24,   95]]],\n",
      "\n",
      "\n",
      "        [[[  52,   70,   63],\n",
      "          [ -28,   47,   25],\n",
      "          [  31,   -7,   46]]],\n",
      "\n",
      "\n",
      "        [[[ -34,   32,   27],\n",
      "          [ -40,  -10,  -36],\n",
      "          [ -21,   -3,  -39]]],\n",
      "\n",
      "\n",
      "        [[[ -43,  -41,   30],\n",
      "          [   2,  -51,  -39],\n",
      "          [  57,   -4,  -29]]],\n",
      "\n",
      "\n",
      "        [[[  30,   -5,  -46],\n",
      "          [ -42,  -62,  -40],\n",
      "          [  64,   12,   88]]],\n",
      "\n",
      "\n",
      "        [[[  76,   78,  -80],\n",
      "          [  45,   52, -100],\n",
      "          [ 102,  100,  -33]]],\n",
      "\n",
      "\n",
      "        [[[ -18,   34,    3],\n",
      "          [ -39,  -49,  -15],\n",
      "          [  23,   24,  -35]]],\n",
      "\n",
      "\n",
      "        [[[   9,   48,   59],\n",
      "          [  65,   68,  -42],\n",
      "          [  42,  -45,  -56]]],\n",
      "\n",
      "\n",
      "        [[[  46,   55,  -35],\n",
      "          [ -22,   61,  -20],\n",
      "          [ -44,   40,   58]]],\n",
      "\n",
      "\n",
      "        [[[  12,  -42,   58],\n",
      "          [  36,  105,   88],\n",
      "          [  74,   88,  -19]]],\n",
      "\n",
      "\n",
      "        [[[ -54,  -56,  -28],\n",
      "          [  24,   49,   31],\n",
      "          [  17,   14,   23]]],\n",
      "\n",
      "\n",
      "        [[[ -31,   39,  -25],\n",
      "          [  11,  -11,  -28],\n",
      "          [ -13,   -6,    3]]],\n",
      "\n",
      "\n",
      "        [[[  35, -116, -112],\n",
      "          [  93,  -28,  -41],\n",
      "          [ 110,   85,   66]]],\n",
      "\n",
      "\n",
      "        [[[  52,   62,   85],\n",
      "          [  61,   22,   58],\n",
      "          [-106,  -92,  -72]]],\n",
      "\n",
      "\n",
      "        [[[  62,  -17,  -70],\n",
      "          [  36,  -13,  -31],\n",
      "          [  62,   41,  -39]]],\n",
      "\n",
      "\n",
      "        [[[ -40,  -24,   40],\n",
      "          [ -10,   16,   63],\n",
      "          [  53,   24,   11]]],\n",
      "\n",
      "\n",
      "        [[[  62,   86,   13],\n",
      "          [   0,   61,   17],\n",
      "          [ -77,   -1,   58]]],\n",
      "\n",
      "\n",
      "        [[[  24,  -43,   -3],\n",
      "          [  26,  -23,  -54],\n",
      "          [  69,    9,   35]]],\n",
      "\n",
      "\n",
      "        [[[  42,  -38,  -37],\n",
      "          [  37,   51,  -38],\n",
      "          [ -20,   46,   20]]],\n",
      "\n",
      "\n",
      "        [[[ -33,  -54,  -63],\n",
      "          [ -35,  -54,   31],\n",
      "          [ -81,   20,   64]]],\n",
      "\n",
      "\n",
      "        [[[  42,   74,  -57],\n",
      "          [  -8,   78,  -27],\n",
      "          [  48,   85,   68]]],\n",
      "\n",
      "\n",
      "        [[[  70,   31,  -27],\n",
      "          [   7,   81,   87],\n",
      "          [ -85,  -40,   55]]],\n",
      "\n",
      "\n",
      "        [[[ -14,  -61,  -43],\n",
      "          [ -18,  -23,  -44],\n",
      "          [  74,   71,    6]]],\n",
      "\n",
      "\n",
      "        [[[ -29,   18,   25],\n",
      "          [  11,   22,  -30],\n",
      "          [ -14,  -36,  -19]]],\n",
      "\n",
      "\n",
      "        [[[ 100,   29, -128],\n",
      "          [  83,   69,  -31],\n",
      "          [  41,  107,  101]]],\n",
      "\n",
      "\n",
      "        [[[  16,   15,   74],\n",
      "          [  63,   70,   20],\n",
      "          [  28,  -14,  -78]]],\n",
      "\n",
      "\n",
      "        [[[  62,  -62,  -31],\n",
      "          [  67,  -13,  -23],\n",
      "          [  46,   41,   25]]],\n",
      "\n",
      "\n",
      "        [[[  38,   44,  -26],\n",
      "          [  10,  -25,  -13],\n",
      "          [   3,   48,   35]]],\n",
      "\n",
      "\n",
      "        [[[  58,   15,  -55],\n",
      "          [   1,   68,   48],\n",
      "          [ -36,   16,   61]]],\n",
      "\n",
      "\n",
      "        [[[  58,   10,   19],\n",
      "          [ -17,   53,   57],\n",
      "          [ -41,  -62,   32]]],\n",
      "\n",
      "\n",
      "        [[[ -36,  -32,   49],\n",
      "          [ -33,  -34,   64],\n",
      "          [ -14,  -20,   54]]],\n",
      "\n",
      "\n",
      "        [[[   3,   52,   65],\n",
      "          [ -50,   -6,   55],\n",
      "          [ -48,  -68,   10]]],\n",
      "\n",
      "\n",
      "        [[[  72,   81,   50],\n",
      "          [  81,   82,  -70],\n",
      "          [  87,  -29,  -79]]],\n",
      "\n",
      "\n",
      "        [[[  25,   72,   62],\n",
      "          [  -3,   78,   58],\n",
      "          [  27,   73,   61]]],\n",
      "\n",
      "\n",
      "        [[[ -47, -122,  -77],\n",
      "          [  35,  -35,  -27],\n",
      "          [  67,  116,   99]]],\n",
      "\n",
      "\n",
      "        [[[  11,  -30,   -8],\n",
      "          [ -35,    9,  -22],\n",
      "          [ -29,   13,  -28]]],\n",
      "\n",
      "\n",
      "        [[[  18,   -9,   56],\n",
      "          [ -28,   10,   63],\n",
      "          [  17,   16,   14]]],\n",
      "\n",
      "\n",
      "        [[[ -40,  -22,  -12],\n",
      "          [ -30,  -44,  -22],\n",
      "          [ -28,   63,   73]]],\n",
      "\n",
      "\n",
      "        [[[ -14,   14,  -41],\n",
      "          [  56,   29,   77],\n",
      "          [  19,  -13,   55]]],\n",
      "\n",
      "\n",
      "        [[[  36,  -14,  -32],\n",
      "          [  53,  -37,  -29],\n",
      "          [  -5,   30,   29]]],\n",
      "\n",
      "\n",
      "        [[[  16,   30,   45],\n",
      "          [ -47,  -15,   16],\n",
      "          [ -30,  -15,  -51]]],\n",
      "\n",
      "\n",
      "        [[[ 102,   83,  -43],\n",
      "          [ 110,   11,  -87],\n",
      "          [  52,  -67, -106]]],\n",
      "\n",
      "\n",
      "        [[[ -81,  -14,   66],\n",
      "          [  61,   69,   62],\n",
      "          [  64,    1,   57]]],\n",
      "\n",
      "\n",
      "        [[[ -58,  -98,  -28],\n",
      "          [  65,   67,  113],\n",
      "          [  74,   79,   10]]],\n",
      "\n",
      "\n",
      "        [[[  69,  113,  108],\n",
      "          [ -71,  -51,    6],\n",
      "          [ -70,  -88,  -66]]],\n",
      "\n",
      "\n",
      "        [[[ -47,  -45,   30],\n",
      "          [ -38,  -15,   33],\n",
      "          [  14,   53,   63]]],\n",
      "\n",
      "\n",
      "        [[[  85,   17,  -91],\n",
      "          [  62,   51,   14],\n",
      "          [ -18,  104,   91]]],\n",
      "\n",
      "\n",
      "        [[[   7,   28,   53],\n",
      "          [ -46,  -51,    6],\n",
      "          [  -6,    6,  -50]]],\n",
      "\n",
      "\n",
      "        [[[  23,   84,   44],\n",
      "          [ -52,   19,   54],\n",
      "          [ -73,  -94,  -37]]],\n",
      "\n",
      "\n",
      "        [[[  51,   75,   32],\n",
      "          [ -28,  -32,   13],\n",
      "          [ -48,  -35,  -46]]],\n",
      "\n",
      "\n",
      "        [[[  -1,  -78,  -28],\n",
      "          [ -19,  -56,    2],\n",
      "          [  81,   71,   64]]],\n",
      "\n",
      "\n",
      "        [[[ -38,  -33,   70],\n",
      "          [  -6,  -38,   47],\n",
      "          [ -42,  -32,   -6]]]], dtype=torch.int8)\n"
     ]
    }
   ],
   "source": [
    "print(\"Weights after quantization\")\n",
    "\n",
    "print(torch.int_repr(model_quantized.features[0].weight()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now lets compute the weights of original model vs quantized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original weights : \n",
      "Parameter containing:\n",
      "tensor([[[[-0.1353, -0.1419, -0.0434],\n",
      "          [ 0.0388,  0.0791, -0.0228],\n",
      "          [ 0.1248,  0.0267,  0.0808]]],\n",
      "\n",
      "\n",
      "        [[[-0.0350, -0.0234,  0.0229],\n",
      "          [ 0.0282, -0.0279, -0.0343],\n",
      "          [-0.0321,  0.0044,  0.0125]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1268,  0.1575,  0.1537],\n",
      "          [-0.0658, -0.0330,  0.0969],\n",
      "          [-0.1846, -0.1450, -0.0596]]],\n",
      "\n",
      "\n",
      "        [[[-0.1512, -0.1831, -0.1003],\n",
      "          [ 0.0767,  0.0528, -0.0415],\n",
      "          [ 0.0990,  0.0571,  0.1365]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1077,  0.0938, -0.0885],\n",
      "          [ 0.1360, -0.0003, -0.1176],\n",
      "          [ 0.1051, -0.0671, -0.0822]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0459, -0.0513,  0.0994],\n",
      "          [-0.0632, -0.0711,  0.1102],\n",
      "          [-0.0419,  0.0420,  0.1134]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1847,  0.2070,  0.2334],\n",
      "          [-0.0818, -0.0393, -0.1071],\n",
      "          [-0.1200, -0.2150, -0.0980]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2195,  0.0905, -0.1054],\n",
      "          [ 0.1940, -0.0363, -0.1808],\n",
      "          [ 0.2136,  0.0860, -0.1380]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1894,  0.2157,  0.1224],\n",
      "          [-0.0796, -0.0303,  0.0200],\n",
      "          [-0.2123, -0.1351, -0.0079]]],\n",
      "\n",
      "\n",
      "        [[[-0.0419, -0.0553, -0.0267],\n",
      "          [ 0.0010, -0.0184,  0.0157],\n",
      "          [-0.0299, -0.0479, -0.0045]]],\n",
      "\n",
      "\n",
      "        [[[-0.0804, -0.1048,  0.0068],\n",
      "          [-0.0449, -0.1036, -0.0743],\n",
      "          [ 0.1749,  0.1292,  0.0317]]],\n",
      "\n",
      "\n",
      "        [[[-0.0926,  0.0798,  0.0980],\n",
      "          [-0.0126,  0.1396,  0.1621],\n",
      "          [ 0.1310,  0.1163,  0.0405]]],\n",
      "\n",
      "\n",
      "        [[[-0.1416, -0.0850,  0.1013],\n",
      "          [-0.0905, -0.0467,  0.1132],\n",
      "          [-0.0933,  0.0466,  0.1858]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1005,  0.1372,  0.1219],\n",
      "          [-0.0542,  0.0916,  0.0479],\n",
      "          [ 0.0614, -0.0143,  0.0895]]],\n",
      "\n",
      "\n",
      "        [[[-0.0667,  0.0617,  0.0519],\n",
      "          [-0.0777, -0.0194, -0.0694],\n",
      "          [-0.0412, -0.0058, -0.0766]]],\n",
      "\n",
      "\n",
      "        [[[-0.0831, -0.0799,  0.0579],\n",
      "          [ 0.0045, -0.0992, -0.0758],\n",
      "          [ 0.1107, -0.0076, -0.0565]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0594, -0.0100, -0.0890],\n",
      "          [-0.0824, -0.1199, -0.0770],\n",
      "          [ 0.1248,  0.0230,  0.1719]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1479,  0.1530, -0.1553],\n",
      "          [ 0.0886,  0.1017, -0.1939],\n",
      "          [ 0.1988,  0.1949, -0.0637]]],\n",
      "\n",
      "\n",
      "        [[[-0.0343,  0.0663,  0.0049],\n",
      "          [-0.0758, -0.0948, -0.0290],\n",
      "          [ 0.0445,  0.0460, -0.0690]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0176,  0.0933,  0.1157],\n",
      "          [ 0.1260,  0.1335, -0.0824],\n",
      "          [ 0.0823, -0.0876, -0.1082]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0888,  0.1070, -0.0675],\n",
      "          [-0.0429,  0.1191, -0.0387],\n",
      "          [-0.0864,  0.0779,  0.1139]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0242, -0.0815,  0.1138],\n",
      "          [ 0.0697,  0.2045,  0.1706],\n",
      "          [ 0.1440,  0.1714, -0.0369]]],\n",
      "\n",
      "\n",
      "        [[[-0.1053, -0.1091, -0.0542],\n",
      "          [ 0.0472,  0.0951,  0.0603],\n",
      "          [ 0.0335,  0.0277,  0.0456]]],\n",
      "\n",
      "\n",
      "        [[[-0.0610,  0.0751, -0.0486],\n",
      "          [ 0.0221, -0.0217, -0.0548],\n",
      "          [-0.0257, -0.0126,  0.0061]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0681, -0.2268, -0.2180],\n",
      "          [ 0.1818, -0.0540, -0.0802],\n",
      "          [ 0.2153,  0.1661,  0.1281]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1017,  0.1213,  0.1663],\n",
      "          [ 0.1181,  0.0420,  0.1132],\n",
      "          [-0.2072, -0.1787, -0.1398]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1203, -0.0324, -0.1365],\n",
      "          [ 0.0711, -0.0244, -0.0600],\n",
      "          [ 0.1218,  0.0803, -0.0768]]],\n",
      "\n",
      "\n",
      "        [[[-0.0774, -0.0462,  0.0773],\n",
      "          [-0.0190,  0.0314,  0.1219],\n",
      "          [ 0.1031,  0.0460,  0.0205]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1211,  0.1674,  0.0244],\n",
      "          [ 0.0004,  0.1192,  0.0333],\n",
      "          [-0.1494, -0.0018,  0.1135]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0462, -0.0832, -0.0055],\n",
      "          [ 0.0499, -0.0452, -0.1044],\n",
      "          [ 0.1352,  0.0178,  0.0682]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0817, -0.0739, -0.0728],\n",
      "          [ 0.0715,  0.0987, -0.0742],\n",
      "          [-0.0393,  0.0905,  0.0387]]],\n",
      "\n",
      "\n",
      "        [[[-0.0643, -0.1052, -0.1219],\n",
      "          [-0.0688, -0.1047,  0.0611],\n",
      "          [-0.1587,  0.0388,  0.1251]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0814,  0.1439, -0.1102],\n",
      "          [-0.0164,  0.1526, -0.0522],\n",
      "          [ 0.0940,  0.1661,  0.1325]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1371,  0.0601, -0.0531],\n",
      "          [ 0.0140,  0.1569,  0.1692],\n",
      "          [-0.1661, -0.0788,  0.1079]]],\n",
      "\n",
      "\n",
      "        [[[-0.0270, -0.1198, -0.0839],\n",
      "          [-0.0351, -0.0452, -0.0863],\n",
      "          [ 0.1441,  0.1394,  0.0119]]],\n",
      "\n",
      "\n",
      "        [[[-0.0574,  0.0354,  0.0485],\n",
      "          [ 0.0207,  0.0428, -0.0591],\n",
      "          [-0.0281, -0.0698, -0.0365]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1958,  0.0567, -0.2485],\n",
      "          [ 0.1625,  0.1348, -0.0600],\n",
      "          [ 0.0807,  0.2088,  0.1964]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0313,  0.0294,  0.1447],\n",
      "          [ 0.1221,  0.1372,  0.0398],\n",
      "          [ 0.0542, -0.0282, -0.1529]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1201, -0.1205, -0.0597],\n",
      "          [ 0.1303, -0.0245, -0.0455],\n",
      "          [ 0.0895,  0.0800,  0.0481]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0736,  0.0855, -0.0512],\n",
      "          [ 0.0200, -0.0480, -0.0253],\n",
      "          [ 0.0049,  0.0935,  0.0685]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1128,  0.0292, -0.1065],\n",
      "          [ 0.0019,  0.1326,  0.0942],\n",
      "          [-0.0702,  0.0306,  0.1186]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1137,  0.0191,  0.0378],\n",
      "          [-0.0322,  0.1034,  0.1114],\n",
      "          [-0.0793, -0.1203,  0.0617]]],\n",
      "\n",
      "\n",
      "        [[[-0.0704, -0.0622,  0.0955],\n",
      "          [-0.0640, -0.0663,  0.1243],\n",
      "          [-0.0273, -0.0395,  0.1057]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0050,  0.1013,  0.1274],\n",
      "          [-0.0980, -0.0117,  0.1081],\n",
      "          [-0.0940, -0.1318,  0.0188]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1405,  0.1585,  0.0977],\n",
      "          [ 0.1577,  0.1607, -0.1370],\n",
      "          [ 0.1693, -0.0562, -0.1532]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0487,  0.1401,  0.1218],\n",
      "          [-0.0056,  0.1524,  0.1128],\n",
      "          [ 0.0529,  0.1419,  0.1198]]],\n",
      "\n",
      "\n",
      "        [[[-0.0925, -0.2370, -0.1510],\n",
      "          [ 0.0679, -0.0685, -0.0526],\n",
      "          [ 0.1304,  0.2269,  0.1934]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0208, -0.0585, -0.0147],\n",
      "          [-0.0688,  0.0181, -0.0437],\n",
      "          [-0.0571,  0.0260, -0.0547]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0355, -0.0173,  0.1099],\n",
      "          [-0.0538,  0.0186,  0.1228],\n",
      "          [ 0.0331,  0.0312,  0.0279]]],\n",
      "\n",
      "\n",
      "        [[[-0.0785, -0.0437, -0.0243],\n",
      "          [-0.0590, -0.0866, -0.0422],\n",
      "          [-0.0544,  0.1231,  0.1424]]],\n",
      "\n",
      "\n",
      "        [[[-0.0281,  0.0267, -0.0801],\n",
      "          [ 0.1100,  0.0562,  0.1508],\n",
      "          [ 0.0374, -0.0258,  0.1065]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0702, -0.0274, -0.0623],\n",
      "          [ 0.1043, -0.0720, -0.0558],\n",
      "          [-0.0101,  0.0588,  0.0563]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0311,  0.0586,  0.0883],\n",
      "          [-0.0920, -0.0296,  0.0310],\n",
      "          [-0.0581, -0.0297, -0.0995]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1986,  0.1623, -0.0844],\n",
      "          [ 0.2153,  0.0213, -0.1688],\n",
      "          [ 0.1014, -0.1307, -0.2062]]],\n",
      "\n",
      "\n",
      "        [[[-0.1588, -0.0281,  0.1284],\n",
      "          [ 0.1197,  0.1347,  0.1200],\n",
      "          [ 0.1251,  0.0010,  0.1105]]],\n",
      "\n",
      "\n",
      "        [[[-0.1125, -0.1913, -0.0538],\n",
      "          [ 0.1263,  0.1297,  0.2195],\n",
      "          [ 0.1447,  0.1534,  0.0185]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1353,  0.2195,  0.2109],\n",
      "          [-0.1377, -0.0999,  0.0114],\n",
      "          [-0.1372, -0.1723, -0.1291]]],\n",
      "\n",
      "\n",
      "        [[[-0.0923, -0.0873,  0.0590],\n",
      "          [-0.0745, -0.0286,  0.0638],\n",
      "          [ 0.0270,  0.1026,  0.1228]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1658,  0.0340, -0.1765],\n",
      "          [ 0.1214,  0.0994,  0.0278],\n",
      "          [-0.0346,  0.2027,  0.1775]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0138,  0.0550,  0.1024],\n",
      "          [-0.0906, -0.1001,  0.0121],\n",
      "          [-0.0111,  0.0114, -0.0969]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0450,  0.1630,  0.0861],\n",
      "          [-0.1016,  0.0363,  0.1059],\n",
      "          [-0.1429, -0.1841, -0.0725]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0989,  0.1469,  0.0618],\n",
      "          [-0.0545, -0.0615,  0.0261],\n",
      "          [-0.0929, -0.0679, -0.0891]]],\n",
      "\n",
      "\n",
      "        [[[-0.0029, -0.1518, -0.0553],\n",
      "          [-0.0374, -0.1099,  0.0044],\n",
      "          [ 0.1584,  0.1392,  0.1239]]],\n",
      "\n",
      "\n",
      "        [[[-0.0748, -0.0647,  0.1371],\n",
      "          [-0.0111, -0.0734,  0.0917],\n",
      "          [-0.0828, -0.0627, -0.0111]]]], requires_grad=True)\n",
      " \n"
     ]
    }
   ],
   "source": [
    "print(\"original weights : \")\n",
    "\n",
    "print(model.features[0].weight)\n",
    "\n",
    "print(' ')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dequantized weights : \n",
      "tensor([[[[-0.1345, -0.1423, -0.0429],\n",
      "          [ 0.0390,  0.0799, -0.0234],\n",
      "          [ 0.1247,  0.0273,  0.0799]]],\n",
      "\n",
      "\n",
      "        [[[-0.0351, -0.0234,  0.0234],\n",
      "          [ 0.0273, -0.0273, -0.0351],\n",
      "          [-0.0312,  0.0039,  0.0117]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1267,  0.1579,  0.1540],\n",
      "          [-0.0663, -0.0331,  0.0975],\n",
      "          [-0.1852, -0.1442, -0.0604]]],\n",
      "\n",
      "\n",
      "        [[[-0.1520, -0.1832, -0.0994],\n",
      "          [ 0.0760,  0.0526, -0.0409],\n",
      "          [ 0.0994,  0.0565,  0.1364]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1072,  0.0936, -0.0877],\n",
      "          [ 0.1364,  0.0000, -0.1169],\n",
      "          [ 0.1052, -0.0663, -0.0819]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0468, -0.0507,  0.0994],\n",
      "          [-0.0624, -0.0702,  0.1111],\n",
      "          [-0.0409,  0.0429,  0.1130]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1852,  0.2066,  0.2339],\n",
      "          [-0.0819, -0.0390, -0.1072],\n",
      "          [-0.1208, -0.2144, -0.0975]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2202,  0.0897, -0.1052],\n",
      "          [ 0.1949, -0.0370, -0.1813],\n",
      "          [ 0.2144,  0.0858, -0.1384]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1891,  0.2163,  0.1228],\n",
      "          [-0.0799, -0.0312,  0.0195],\n",
      "          [-0.2124, -0.1345, -0.0078]]],\n",
      "\n",
      "\n",
      "        [[[-0.0409, -0.0546, -0.0273],\n",
      "          [ 0.0019, -0.0175,  0.0156],\n",
      "          [-0.0292, -0.0487, -0.0039]]],\n",
      "\n",
      "\n",
      "        [[[-0.0799, -0.1052,  0.0058],\n",
      "          [-0.0448, -0.1033, -0.0741],\n",
      "          [ 0.1754,  0.1286,  0.0312]]],\n",
      "\n",
      "\n",
      "        [[[-0.0916,  0.0799,  0.0975],\n",
      "          [-0.0117,  0.1403,  0.1618],\n",
      "          [ 0.1306,  0.1169,  0.0409]]],\n",
      "\n",
      "\n",
      "        [[[-0.1423, -0.0858,  0.1013],\n",
      "          [-0.0897, -0.0468,  0.1130],\n",
      "          [-0.0936,  0.0468,  0.1852]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1013,  0.1364,  0.1228],\n",
      "          [-0.0546,  0.0916,  0.0487],\n",
      "          [ 0.0604, -0.0136,  0.0897]]],\n",
      "\n",
      "\n",
      "        [[[-0.0663,  0.0624,  0.0526],\n",
      "          [-0.0780, -0.0195, -0.0702],\n",
      "          [-0.0409, -0.0058, -0.0760]]],\n",
      "\n",
      "\n",
      "        [[[-0.0838, -0.0799,  0.0585],\n",
      "          [ 0.0039, -0.0994, -0.0760],\n",
      "          [ 0.1111, -0.0078, -0.0565]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0585, -0.0097, -0.0897],\n",
      "          [-0.0819, -0.1208, -0.0780],\n",
      "          [ 0.1247,  0.0234,  0.1715]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1481,  0.1520, -0.1559],\n",
      "          [ 0.0877,  0.1013, -0.1949],\n",
      "          [ 0.1988,  0.1949, -0.0643]]],\n",
      "\n",
      "\n",
      "        [[[-0.0351,  0.0663,  0.0058],\n",
      "          [-0.0760, -0.0955, -0.0292],\n",
      "          [ 0.0448,  0.0468, -0.0682]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0175,  0.0936,  0.1150],\n",
      "          [ 0.1267,  0.1325, -0.0819],\n",
      "          [ 0.0819, -0.0877, -0.1091]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0897,  0.1072, -0.0682],\n",
      "          [-0.0429,  0.1189, -0.0390],\n",
      "          [-0.0858,  0.0780,  0.1130]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0234, -0.0819,  0.1130],\n",
      "          [ 0.0702,  0.2046,  0.1715],\n",
      "          [ 0.1442,  0.1715, -0.0370]]],\n",
      "\n",
      "\n",
      "        [[[-0.1052, -0.1091, -0.0546],\n",
      "          [ 0.0468,  0.0955,  0.0604],\n",
      "          [ 0.0331,  0.0273,  0.0448]]],\n",
      "\n",
      "\n",
      "        [[[-0.0604,  0.0760, -0.0487],\n",
      "          [ 0.0214, -0.0214, -0.0546],\n",
      "          [-0.0253, -0.0117,  0.0058]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0682, -0.2261, -0.2183],\n",
      "          [ 0.1813, -0.0546, -0.0799],\n",
      "          [ 0.2144,  0.1657,  0.1286]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1013,  0.1208,  0.1657],\n",
      "          [ 0.1189,  0.0429,  0.1130],\n",
      "          [-0.2066, -0.1793, -0.1403]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1208, -0.0331, -0.1364],\n",
      "          [ 0.0702, -0.0253, -0.0604],\n",
      "          [ 0.1208,  0.0799, -0.0760]]],\n",
      "\n",
      "\n",
      "        [[[-0.0780, -0.0468,  0.0780],\n",
      "          [-0.0195,  0.0312,  0.1228],\n",
      "          [ 0.1033,  0.0468,  0.0214]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1208,  0.1676,  0.0253],\n",
      "          [ 0.0000,  0.1189,  0.0331],\n",
      "          [-0.1501, -0.0019,  0.1130]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0468, -0.0838, -0.0058],\n",
      "          [ 0.0507, -0.0448, -0.1052],\n",
      "          [ 0.1345,  0.0175,  0.0682]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0819, -0.0741, -0.0721],\n",
      "          [ 0.0721,  0.0994, -0.0741],\n",
      "          [-0.0390,  0.0897,  0.0390]]],\n",
      "\n",
      "\n",
      "        [[[-0.0643, -0.1052, -0.1228],\n",
      "          [-0.0682, -0.1052,  0.0604],\n",
      "          [-0.1579,  0.0390,  0.1247]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0819,  0.1442, -0.1111],\n",
      "          [-0.0156,  0.1520, -0.0526],\n",
      "          [ 0.0936,  0.1657,  0.1325]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1364,  0.0604, -0.0526],\n",
      "          [ 0.0136,  0.1579,  0.1696],\n",
      "          [-0.1657, -0.0780,  0.1072]]],\n",
      "\n",
      "\n",
      "        [[[-0.0273, -0.1189, -0.0838],\n",
      "          [-0.0351, -0.0448, -0.0858],\n",
      "          [ 0.1442,  0.1384,  0.0117]]],\n",
      "\n",
      "\n",
      "        [[[-0.0565,  0.0351,  0.0487],\n",
      "          [ 0.0214,  0.0429, -0.0585],\n",
      "          [-0.0273, -0.0702, -0.0370]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1949,  0.0565, -0.2495],\n",
      "          [ 0.1618,  0.1345, -0.0604],\n",
      "          [ 0.0799,  0.2085,  0.1969]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0312,  0.0292,  0.1442],\n",
      "          [ 0.1228,  0.1364,  0.0390],\n",
      "          [ 0.0546, -0.0273, -0.1520]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1208, -0.1208, -0.0604],\n",
      "          [ 0.1306, -0.0253, -0.0448],\n",
      "          [ 0.0897,  0.0799,  0.0487]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0741,  0.0858, -0.0507],\n",
      "          [ 0.0195, -0.0487, -0.0253],\n",
      "          [ 0.0058,  0.0936,  0.0682]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1130,  0.0292, -0.1072],\n",
      "          [ 0.0019,  0.1325,  0.0936],\n",
      "          [-0.0702,  0.0312,  0.1189]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1130,  0.0195,  0.0370],\n",
      "          [-0.0331,  0.1033,  0.1111],\n",
      "          [-0.0799, -0.1208,  0.0624]]],\n",
      "\n",
      "\n",
      "        [[[-0.0702, -0.0624,  0.0955],\n",
      "          [-0.0643, -0.0663,  0.1247],\n",
      "          [-0.0273, -0.0390,  0.1052]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0058,  0.1013,  0.1267],\n",
      "          [-0.0975, -0.0117,  0.1072],\n",
      "          [-0.0936, -0.1325,  0.0195]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1403,  0.1579,  0.0975],\n",
      "          [ 0.1579,  0.1598, -0.1364],\n",
      "          [ 0.1696, -0.0565, -0.1540]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0487,  0.1403,  0.1208],\n",
      "          [-0.0058,  0.1520,  0.1130],\n",
      "          [ 0.0526,  0.1423,  0.1189]]],\n",
      "\n",
      "\n",
      "        [[[-0.0916, -0.2378, -0.1501],\n",
      "          [ 0.0682, -0.0682, -0.0526],\n",
      "          [ 0.1306,  0.2261,  0.1930]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0214, -0.0585, -0.0156],\n",
      "          [-0.0682,  0.0175, -0.0429],\n",
      "          [-0.0565,  0.0253, -0.0546]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0351, -0.0175,  0.1091],\n",
      "          [-0.0546,  0.0195,  0.1228],\n",
      "          [ 0.0331,  0.0312,  0.0273]]],\n",
      "\n",
      "\n",
      "        [[[-0.0780, -0.0429, -0.0234],\n",
      "          [-0.0585, -0.0858, -0.0429],\n",
      "          [-0.0546,  0.1228,  0.1423]]],\n",
      "\n",
      "\n",
      "        [[[-0.0273,  0.0273, -0.0799],\n",
      "          [ 0.1091,  0.0565,  0.1501],\n",
      "          [ 0.0370, -0.0253,  0.1072]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0702, -0.0273, -0.0624],\n",
      "          [ 0.1033, -0.0721, -0.0565],\n",
      "          [-0.0097,  0.0585,  0.0565]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0312,  0.0585,  0.0877],\n",
      "          [-0.0916, -0.0292,  0.0312],\n",
      "          [-0.0585, -0.0292, -0.0994]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1988,  0.1618, -0.0838],\n",
      "          [ 0.2144,  0.0214, -0.1696],\n",
      "          [ 0.1013, -0.1306, -0.2066]]],\n",
      "\n",
      "\n",
      "        [[[-0.1579, -0.0273,  0.1286],\n",
      "          [ 0.1189,  0.1345,  0.1208],\n",
      "          [ 0.1247,  0.0019,  0.1111]]],\n",
      "\n",
      "\n",
      "        [[[-0.1130, -0.1910, -0.0546],\n",
      "          [ 0.1267,  0.1306,  0.2202],\n",
      "          [ 0.1442,  0.1540,  0.0195]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1345,  0.2202,  0.2105],\n",
      "          [-0.1384, -0.0994,  0.0117],\n",
      "          [-0.1364, -0.1715, -0.1286]]],\n",
      "\n",
      "\n",
      "        [[[-0.0916, -0.0877,  0.0585],\n",
      "          [-0.0741, -0.0292,  0.0643],\n",
      "          [ 0.0273,  0.1033,  0.1228]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1657,  0.0331, -0.1774],\n",
      "          [ 0.1208,  0.0994,  0.0273],\n",
      "          [-0.0351,  0.2027,  0.1774]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0136,  0.0546,  0.1033],\n",
      "          [-0.0897, -0.0994,  0.0117],\n",
      "          [-0.0117,  0.0117, -0.0975]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0448,  0.1637,  0.0858],\n",
      "          [-0.1013,  0.0370,  0.1052],\n",
      "          [-0.1423, -0.1832, -0.0721]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0994,  0.1462,  0.0624],\n",
      "          [-0.0546, -0.0624,  0.0253],\n",
      "          [-0.0936, -0.0682, -0.0897]]],\n",
      "\n",
      "\n",
      "        [[[-0.0019, -0.1520, -0.0546],\n",
      "          [-0.0370, -0.1091,  0.0039],\n",
      "          [ 0.1579,  0.1384,  0.1247]]],\n",
      "\n",
      "\n",
      "        [[[-0.0741, -0.0643,  0.1364],\n",
      "          [-0.0117, -0.0741,  0.0916],\n",
      "          [-0.0819, -0.0624, -0.0117]]]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Dequantized weights : \")\n",
    "\n",
    "print(torch.dequantize(model_quantized.features[0].weight()))\n",
    "\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now lets compare the size of original model vs quantized model|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the model before quantization\n",
      "Size (KB) : 13325.89\n"
     ]
    }
   ],
   "source": [
    "print('Size of the model before quantization')\n",
    "print_size_of_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the model after quantization\n",
      "Size (KB) : 3344.358\n"
     ]
    }
   ],
   "source": [
    "print('Size of the model after quantization')\n",
    "print_size_of_model(model_quantized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI702",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
